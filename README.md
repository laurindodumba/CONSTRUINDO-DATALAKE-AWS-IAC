# ğŸš€ AWS Data Engineering Pipeline

Este repositÃ³rio contÃ©m um **pipeline de engenharia de dados na AWS**, seguindo boas prÃ¡ticas de **Data Lake**, **arquitetura em camadas (Bronze / Silver / Gold)** e automaÃ§Ã£o para ingestÃ£o, transformaÃ§Ã£o e disponibilizaÃ§Ã£o de dados para anÃ¡lise.

---

## ğŸ“Œ VisÃ£o Geral

O objetivo deste projeto Ã© demonstrar a construÃ§Ã£o de um pipeline de dados escalÃ¡vel e confiÃ¡vel utilizando serviÃ§os da AWS, desde a extraÃ§Ã£o de dados de fontes externas atÃ© a disponibilizaÃ§Ã£o para consumo analÃ­tico.

**Principais caracterÃ­sticas:**
- IngestÃ£o de dados via API / arquivos
- Armazenamento em Data Lake (Amazon S3)
- Processamento e transformaÃ§Ã£o de dados
- OrganizaÃ§Ã£o em camadas (Bronze, Silver e Gold)
- CÃ³digo modular e reutilizÃ¡vel

---

## ğŸ—ï¸ Arquitetura do Pipeline

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Source  â”‚  (API / CSV / JSON)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ S3 - Bronze Layer  â”‚  (Raw data)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ S3 - Silver Layer  â”‚  (Cleaned & standardized)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ S3 - Gold Layer    â”‚  (Business-ready data)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§± Data Lake Layers

### ğŸ¥‰ Bronze (Raw)
- Dados brutos
- Sem transformaÃ§Ãµes
- Fonte original preservada

### ğŸ¥ˆ Silver (Trusted)
- Limpeza de dados
- PadronizaÃ§Ã£o de tipos
- Tratamento de valores nulos

### ğŸ¥‡ Gold (Analytics)
- Dados agregados
- MÃ©tricas de negÃ³cio
- Prontos para consumo (BI / ML)

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **AWS S3** â€“ Data Lake
- **AWS IAM** â€“ Controle de acesso
- **Python 3** â€“ Linguagem principal
- **Boto3** â€“ IntegraÃ§Ã£o com AWS
- **Pandas / PySpark** â€“ TransformaÃ§Ãµes de dados
- **Git & GitHub** â€“ Versionamento

---

## ğŸ“‚ Estrutura do Projeto

```text
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ silver/
â”‚   â””â”€â”€ gold/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â”œâ”€â”€ load.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš™ï¸ ConfiguraÃ§Ã£o do Ambiente

### 1ï¸âƒ£ Clonar o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
```

### 2ï¸âƒ£ Criar ambiente virtual

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\\Scripts\\activate     # Windows
```

### 3ï¸âƒ£ Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configurar credenciais AWS

```bash
aws configure
```

---

## â–¶ï¸ ExecuÃ§Ã£o do Pipeline

```bash
python src/main.py
```

Fluxo executado:
1. ExtraÃ§Ã£o dos dados
2. Upload para camada Bronze
3. TransformaÃ§Ãµes (Silver)
4. AgregaÃ§Ãµes finais (Gold)

---

## ğŸ” SeguranÃ§a e Boas PrÃ¡ticas

- PrincÃ­pio do menor privilÃ©gio (IAM)
- SeparaÃ§Ã£o de permissÃµes por camada
- NÃ£o versionar credenciais
- Uso de variÃ¡veis de ambiente

---

## ğŸ“ˆ PossÃ­veis EvoluÃ§Ãµes

- OrquestraÃ§Ã£o com Apache Airflow
- Processamento distribuÃ­do com AWS Glue / Spark
- CatÃ¡logo de dados com AWS Glue Data Catalog
- Monitoramento com CloudWatch
- CI/CD com GitHub Actions

---

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas!

1. FaÃ§a um fork do projeto
2. Crie uma branch (`feature/nova-feature`)
3. Commit suas alteraÃ§Ãµes
4. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

## ğŸ‘¤ Autor

**Laurindo Dumba**  
Engenheiro de Dados | Cloud & Analytics  

ğŸ”— LinkedIn: https://www.linkedin.com

---

â­ Se este projeto te ajudou, deixe uma estrela no repositÃ³rio!

